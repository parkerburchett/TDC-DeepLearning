{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Model to submit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPmSMcjQ9VSX"
      },
      "source": [
        "### Evalute the WeightedModel on all of the binary classifation task in ADME\n",
        "\n",
        "The models and model weights where tuned on the training data from cyp2c9_veith.\n",
        "\n",
        "The molecules are embedded using ColorRefinement an algorithm I wrote to detect identical arbritaty sized subgrpahs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbWmgF3-ssac",
        "outputId": "9f728d4e-b386-4109-99d2-7e3eb7061b95"
      },
      "source": [
        "!git clone https://github.com/parkerburchett/pysmiles\n",
        "!pip install pyTDC\n",
        "!git clone https://github.com/parkerburchett/TDC-DeepLearning\n",
        "!pip3 install rdkit-pypi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'pysmiles'...\n",
            "remote: Enumerating objects: 420, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 420 (delta 12), reused 18 (delta 4), pack-reused 390\u001b[K\n",
            "Receiving objects: 100% (420/420), 134.29 KiB | 1.66 MiB/s, done.\n",
            "Resolving deltas: 100% (251/251), done.\n",
            "Collecting pyTDC\n",
            "  Downloading PyTDC-0.3.1.tar.gz (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyTDC) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pyTDC) (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pyTDC) (4.62.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyTDC) (0.22.2.post1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from pyTDC) (0.11.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pyTDC) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyTDC) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pyTDC) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyTDC) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyTDC) (1.0.1)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn->pyTDC) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->pyTDC) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->pyTDC) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->pyTDC) (2.4.7)\n",
            "Building wheels for collected packages: pyTDC\n",
            "  Building wheel for pyTDC (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyTDC: filename=PyTDC-0.3.1-py3-none-any.whl size=116110 sha256=0ee772d9050df257fc3e357a13a1e001e427b62617de3e7ca82bb362b6f01666\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/54/07/50251965a66a68eb6c0e2b3022588cc992cc4c2a2e69d8c7ec\n",
            "Successfully built pyTDC\n",
            "Installing collected packages: fuzzywuzzy, pyTDC\n",
            "Successfully installed fuzzywuzzy-0.18.0 pyTDC-0.3.1\n",
            "Cloning into 'TDC-DeepLearning'...\n",
            "remote: Enumerating objects: 264, done.\u001b[K\n",
            "remote: Counting objects: 100% (264/264), done.\u001b[K\n",
            "remote: Compressing objects: 100% (208/208), done.\u001b[K\n",
            "remote: Total 264 (delta 94), reused 220 (delta 51), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (264/264), 49.21 MiB | 4.32 MiB/s, done.\n",
            "Resolving deltas: 100% (94/94), done.\n",
            "Checking out files: 100% (98/98), done.\n",
            "Collecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2021.3.5.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 195 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi) (1.19.5)\n",
            "Installing collected packages: rdkit-pypi\n",
            "Successfully installed rdkit-pypi-2021.3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bitBoDL0srnL"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightgbm import LGBMRegressor\n",
        "from pysmiles.pysmiles import read_smiles\n",
        "import os\n",
        "os.chdir('/content/TDC-DeepLearning/')\n",
        "from utils import ColorRefinement as cr "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T3hQxtv17utE"
      },
      "source": [
        "tuned_weights = np.array([0.23494501, 0.50427143, 0.16934516, 0.0914384])\n",
        "\n",
        "tuned_models = [LGBMRegressor(boosting_type='gbdt', class_weight=None,\n",
        "               colsample_bytree=0.45921506474872353, importance_type='split',\n",
        "               learning_rate=0.003605978989205916, max_depth=-1,\n",
        "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
        "               n_estimators=997, n_jobs=-1, num_leaves=171, objective=None,\n",
        "               random_state=None, reg_alpha=0.06136193030050688, reg_lambda=0.0,\n",
        "               silent=True, subsample=0.664374000848817,\n",
        "               subsample_for_bin=200000, subsample_freq=1),\n",
        " LGBMRegressor(boosting_type='gbdt', class_weight=None,\n",
        "               colsample_bytree=0.19190373976042552, importance_type='split',\n",
        "               learning_rate=0.018880733945270692, max_depth=-1,\n",
        "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
        "               n_estimators=772, n_jobs=-1, num_leaves=412, objective=None,\n",
        "               random_state=None, reg_alpha=0.1319602189105627, reg_lambda=0.0,\n",
        "               silent=True, subsample=0.953435263598222,\n",
        "               subsample_for_bin=200000, subsample_freq=1),\n",
        " LGBMRegressor(boosting_type='gbdt', class_weight=None,\n",
        "               colsample_bytree=0.0846115062976256, importance_type='split',\n",
        "               learning_rate=0.061904626017968235, max_depth=-1,\n",
        "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
        "               n_estimators=710, n_jobs=-1, num_leaves=218, objective=None,\n",
        "               random_state=None, reg_alpha=0.09722107305351997, reg_lambda=0.0,\n",
        "               silent=True, subsample=0.7625401046034898,\n",
        "               subsample_for_bin=200000, subsample_freq=1),\n",
        " LGBMRegressor(boosting_type='gbdt', class_weight=None,\n",
        "               colsample_bytree=0.10234165146414909, importance_type='split',\n",
        "               learning_rate=0.021876318417714605, max_depth=-1,\n",
        "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
        "               n_estimators=574, n_jobs=-1, num_leaves=193, objective=None,\n",
        "               random_state=None, reg_alpha=0.08093256266597965, reg_lambda=0.0,\n",
        "               silent=True, subsample=0.9986613307559011,\n",
        "               subsample_for_bin=200000, subsample_freq=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5j9hsKxguSJ0"
      },
      "source": [
        "class WeightedModel:\n",
        "\n",
        "  def __init__(self,\n",
        "               cr_num_hops:int,\n",
        "               cr_num_colors:int, \n",
        "               models:list,\n",
        "               model_weights:list):\n",
        "    \n",
        "    self.cr_num_hops = cr_num_hops\n",
        "    self.cr_num_colors = cr_num_colors\n",
        "    self.models = models\n",
        "    self.model_weights = model_weights\n",
        "\n",
        "\n",
        "  def _create_embeddings(self, smiles):\n",
        "    graphs = [read_smiles(s,) for s in smiles]\n",
        "    hop_feature_dfs = cr.create_hop_feature_dfs(graphs=graphs,\n",
        "                                                num_hops=self.cr_num_hops,\n",
        "                                                num_colors=self.cr_num_colors)\n",
        "    return hop_feature_dfs\n",
        "\n",
        "\n",
        "  def fit(self, smiles, targets):\n",
        "    hop_feature_dfs = self._create_embeddings(smiles)\n",
        "    print('embedded for fitting')\n",
        "    for hop_num, model in enumerate(self.models):\n",
        "      X = hop_feature_dfs[hop_num].values\n",
        "      y = targets.values\n",
        "      model.fit(X,y)\n",
        "\n",
        "\n",
        "  def predict(self, smiles):\n",
        "    hop_feature_dfs = self._create_embeddings(smiles)\n",
        "    print('embedded for prediction')\n",
        "    prediction_df = pd.DataFrame()\n",
        "    for hop_num, model in enumerate(self.models):\n",
        "      prediction_df[hop_num] = model.predict(hop_feature_dfs[hop_num].values)\n",
        "    weighted_predictions = prediction_df.values.dot(self.model_weights)\n",
        "    return weighted_predictions\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MrBNYwpFI-in"
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve,auc\n",
        "def compute_auprc(y_true,y_pred):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
        "    area = auc(recall, precision)\n",
        "    return area"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "2AXfnHYETI_P",
        "outputId": "aa46039b-972b-41cb-b118-12acd7573eee"
      },
      "source": [
        "%%time\n",
        "from tdc.benchmark_group import admet_group\n",
        "group = admet_group(path = 'data/')\n",
        "benchmark = group.get('cyp2c9_veith')\n",
        "test_predictions_list = []\n",
        "\n",
        "for seed in [1, 2, 3, 4, 5]:\n",
        "  name = benchmark['name']\n",
        "  train_val, test = benchmark['train_val'], benchmark['test']\n",
        "  train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = seed)\n",
        "  final_model = WeightedModel(cr_num_hops=4,\n",
        "                              cr_num_colors=2_000,\n",
        "                              models=tuned_models,\n",
        "                              model_weights=tuned_weights)\n",
        "  \n",
        "  final_model.fit(train['Drug'], train['Y'])\n",
        "  print('fit model')\n",
        "  y_preds = final_model.predict(test['Drug'].values)\n",
        "  predictions = {}\n",
        "  predictions[name] = y_preds\n",
        "  test_predictions_list.append(predictions)\n",
        "\n",
        "  print(compute_auprc(test['Y'].values, y_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found local copy...\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2942.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embedded for fitting\n",
            "fit model\n",
            "embedded for prediction\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "generating training, validation splits...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.762515017335501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9673/9673 [00:03<00:00, 3066.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embedded for fitting\n",
            "fit model\n",
            "embedded for prediction\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "generating training, validation splits...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7690281851884446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9673/9673 [00:03<00:00, 3001.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embedded for fitting\n",
            "fit model\n",
            "embedded for prediction\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "generating training, validation splits...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7661692844559881\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9673/9673 [00:03<00:00, 3018.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embedded for fitting\n",
            "fit model\n",
            "embedded for prediction\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "generating training, validation splits...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7660245925139474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9673/9673 [00:03<00:00, 2921.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embedded for fitting\n",
            "fit model\n",
            "embedded for prediction\n",
            "0.7702735061834148\n",
            "CPU times: user 2h 8min 59s, sys: 42.3 s, total: 2h 9min 41s\n",
            "Wall time: 1h 56min 13s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi7IYeiYTQYk",
        "outputId": "50cefcb9-100a-4781-9e2c-62d13929f24a"
      },
      "source": [
        "group.evaluate_many(test_predictions_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'cyp2c9_veith': [0.767, 0.003]}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    }
  ]
}