{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Save Graph Embeddings to Google Drive with Color Refinement.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8RGlqBu8Dw4"
      },
      "source": [
        "This will compute the 0 - 29 hop embeddings for the in sample data frames\n",
        "\n",
        "This creates 30 (~9k,10k) .csv files in `MyDrive/SpringBoard/Therapeutic Data Commons Projects/data/more_buckets_data/{index}_hop_larger_embedding.csv` where index refers to the hop number.\n",
        "\n",
        "I only expect to use the first few ~10ish dataframes as features since the rest get a lot of random noise. I am including up to 30 since I want to only have to do it once.\n",
        "\n",
        "I have also included the time costs of each of the steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5x0Oumu77Md",
        "outputId": "9a7bfc31-87b9-4f14-a2c3-5e982c780bfb"
      },
      "source": [
        "!git clone https://github.com/parkerburchett/pysmiles # pysmiles just with te\n",
        "!pip install pyTDC\n",
        "!git clone https://github.com/parkerburchett/TDC-DeepLearning"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pysmiles'...\n",
            "remote: Enumerating objects: 420, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 420 (delta 12), reused 18 (delta 4), pack-reused 390\u001b[K\n",
            "Receiving objects: 100% (420/420), 134.29 KiB | 22.38 MiB/s, done.\n",
            "Resolving deltas: 100% (251/251), done.\n",
            "Requirement already satisfied: pyTDC in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from pyTDC) (0.11.2)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.7/dist-packages (from pyTDC) (0.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyTDC) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pyTDC) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyTDC) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pyTDC) (4.62.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyTDC) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pyTDC) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pyTDC) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyTDC) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyTDC) (1.0.1)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn->pyTDC) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->pyTDC) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->pyTDC) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->pyTDC) (1.3.2)\n",
            "Cloning into 'TDC-DeepLearning'...\n",
            "remote: Enumerating objects: 245, done.\u001b[K\n",
            "remote: Counting objects: 100% (245/245), done.\u001b[K\n",
            "remote: Compressing objects: 100% (193/193), done.\u001b[K\n",
            "remote: Total 245 (delta 83), reused 208 (delta 47), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (245/245), 48.62 MiB | 22.28 MiB/s, done.\n",
            "Resolving deltas: 100% (83/83), done.\n",
            "Checking out files: 100% (97/97), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWVhivJ08o7v"
      },
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from pysmiles.pysmiles import read_smiles\n",
        "from tdc.single_pred import ADME\n",
        "import os\n",
        "os.chdir('/content/TDC-DeepLearning/')\n",
        "from utils import ColorRefinement as cr # this is the graph embedding Algo I wrote\n",
        "from sklearn.decomposition import PCA\n",
        "import lightgbm as lgb\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdZPqY3iwr1c",
        "outputId": "057f0bb0-550c-4488-c28c-9c3bb82646c2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU8Y4hyFw2XX",
        "outputId": "e97c2188-5958-46d9-d74c-923571c2dea0"
      },
      "source": [
        "from tdc import utils\n",
        "from tdc.benchmark_group import admet_group\n",
        "\n",
        "group = admet_group(path = 'data/')\n",
        "benchmark = group.get('cyp2c9_veith')\n",
        "training_smiles = benchmark['train_val']['Drug']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found local copy...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95hq73-TxFn2",
        "outputId": "169e973f-4fe7-4a71-9797-3cdc97759337"
      },
      "source": [
        "%%time \n",
        "graphs = [read_smiles(s) for s in training_smiles]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 14 s, sys: 199 ms, total: 14.2 s\n",
            "Wall time: 14.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy7GD2LhxUha"
      },
      "source": [
        "%%time\n",
        "hop_feature_dfs = cr.create_hop_feature_dfs(graphs,\n",
        "                                        num_hops=30, # means 30 dataframes\n",
        "                                        num_colors=10_000) # means 10k columns."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-uGkLAIyQa3"
      },
      "source": [
        "%%time\n",
        "def add_labels_to_df(df):\n",
        "  df.columns = [f'color_{i}' for i in range(len(df.columns))]\n",
        "  df.index.rename('index', inplace=True)\n",
        "  return df\n",
        "\n",
        "for index, df in enumerate(hop_feature_dfs):\n",
        "  save_location =f'/content/drive/MyDrive/SpringBoard/Therapeutic Data Commons Projects/data/more_buckets_data/{index}_hop_larger_embedding.csv'\n",
        "  df = add_labels_to_df(df)\n",
        "  df.to_csv(save_location)\n",
        "  print(f'saved df {index}')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}